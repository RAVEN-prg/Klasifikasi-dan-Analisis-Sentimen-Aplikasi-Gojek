{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WCkKmQq05ku"
      },
      "source": [
        "## PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBnFVXcI0Vy3",
        "outputId": "eeed3079-a853-42ac-ea1d-2b8f9ea44a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install Sastrawi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNYt_ss90IRm",
        "outputId": "5fdf0645-d614-4dcb-d49c-1376bb35eb5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Download NLTK resources (jika belum ada)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Download the missing 'punkt_tab' resource\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Inisialisasi stemmer Sastrawi\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Inisialisasi daftar stopwords Bahasa Indonesia\n",
        "stop_words = set(stopwords.words('indonesian'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znNwfWQ-0g_2",
        "outputId": "b20657d0-78cc-43ac-b242-df06f3442530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contoh Dataset:\n",
            "                  userName                                            content  \\\n",
            "0                Yuga Edit                            akun gopay saya di blok   \n",
            "1                 ff burik  Lambat sekali sekarang ini bosssku apk gojek g...   \n",
            "2  Anisa Suci Rahmayuliani  Kenapa sih dari kemarin sy buka aplikasi gojek...   \n",
            "3             naoki yakuza  Baru download gojek dan hape baru trus ditop u...   \n",
            "4            Trio Sugianto                                             Mantap   \n",
            "\n",
            "   score                   at appVersion  \n",
            "0      1  2022-01-21 10:52:12      4.9.3  \n",
            "1      3  2021-11-30 15:40:38      4.9.3  \n",
            "2      4  2021-11-29 22:58:12      4.9.3  \n",
            "3      1  2022-09-03 15:21:17      4.9.3  \n",
            "4      5  2022-01-15 10:05:27      4.9.3  \n",
            "\n",
            "Jumlah baris data: 225002\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "try:\n",
        "    df = pd.read_csv('GojekAppReview_1.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"File 'GojekAppReview_1.csv' tidak ditemukan. Pastikan file sudah diunggah dengan benar.\")\n",
        "\n",
        "print(\"Contoh Dataset:\")\n",
        "print(df.head())\n",
        "print(f\"\\nJumlah baris data: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dldLdN91AQe"
      },
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pvef0K21Owu"
      },
      "source": [
        "Labelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UadAWVGh1Ec2",
        "outputId": "efa04473-d0d4-416c-d8f3-c13184b25434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset setelah labelling:\n",
            "   score sentiment\n",
            "0      1   negatif\n",
            "1      3    netral\n",
            "2      4   positif\n",
            "3      1   negatif\n",
            "4      5   positif\n",
            "\n",
            "Distribusi Sentimen:\n",
            "sentiment\n",
            "positif    161371\n",
            "negatif     54171\n",
            "netral       9460\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def label_sentiment(score):\n",
        "    if score in [1, 2]:\n",
        "        return 'negatif'\n",
        "    elif score == 3:\n",
        "        return 'netral'\n",
        "    elif score in [4, 5]:\n",
        "        return 'positif'\n",
        "    return None # Untuk skor yang mungkin tidak valid\n",
        "\n",
        "df['sentiment'] = df['score'].apply(label_sentiment)\n",
        "\n",
        "# Hapus baris dengan sentimen yang tidak terdefinisi (jika ada)\n",
        "df.dropna(subset=['sentiment'], inplace=True)\n",
        "\n",
        "print(\"\\nDataset setelah labelling:\")\n",
        "print(df[['score', 'sentiment']].head())\n",
        "print(f\"\\nDistribusi Sentimen:\\n{df['sentiment'].value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hat3-SW1U89"
      },
      "source": [
        "Cleaning Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gtFbTKe1Z8u",
        "outputId": "c23fecba-e20b-4bf9-cd5a-7cf424e2cae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset setelah pembersihan teks:\n",
            "                                             content  \\\n",
            "0                            akun gopay saya di blok   \n",
            "1  Lambat sekali sekarang ini bosssku apk gojek g...   \n",
            "2  Kenapa sih dari kemarin sy buka aplikasi gojek...   \n",
            "3  Baru download gojek dan hape baru trus ditop u...   \n",
            "4                                             Mantap   \n",
            "\n",
            "                                     cleaned_content  \n",
            "0                            akun gopay saya di blok  \n",
            "1  lambat sekali sekarang ini bosssku apk gojek g...  \n",
            "2  kenapa sih dari kemarin sy buka aplikasi gojek...  \n",
            "3  baru download gojek dan hape baru trus ditop u...  \n",
            "4                                             mantap  \n"
          ]
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower() # Lowercasing\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Hapus URL\n",
        "        text = re.sub(r'\\@\\w+|\\#','', text) # Hapus mention dan hashtag\n",
        "        text = re.sub(r'[^\\w\\s]', '', text) # Hapus karakter khusus dan tanda baca\n",
        "        text = re.sub(r'\\d+', '', text) # Hapus angka\n",
        "        # Hapus emoji (basic)\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "        text = emoji_pattern.sub(r'', text)\n",
        "        text = text.strip() # Hapus spasi berlebih di awal dan akhir\n",
        "    return text\n",
        "\n",
        "df['cleaned_content'] = df['content'].apply(clean_text)\n",
        "print(\"\\nDataset setelah pembersihan teks:\")\n",
        "print(df[['content', 'cleaned_content']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbgkH7l31sZu"
      },
      "source": [
        "Normalisasi Kata Tidak Baku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqDMcCWN1tyu",
        "outputId": "56441d87-7ef4-418b-d72e-e1d306877d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset setelah normalisasi kata:\n",
            "                                     cleaned_content  \\\n",
            "0                            akun gopay saya di blok   \n",
            "1  lambat sekali sekarang ini bosssku apk gojek g...   \n",
            "2  kenapa sih dari kemarin sy buka aplikasi gojek...   \n",
            "3  baru download gojek dan hape baru trus ditop u...   \n",
            "4                                             mantap   \n",
            "\n",
            "                                  normalized_content  \n",
            "0                            akun gopay saya di blok  \n",
            "1  lambat sekali sekarang ini bosku aplikasi goje...  \n",
            "2  kenapa  dari kemarin saya buka aplikasi gojek ...  \n",
            "3  baru download gojek dan hape baru terus ditop ...  \n",
            "4                                             mantap  \n"
          ]
        }
      ],
      "source": [
        "normalization_dict = {\n",
        "    'yg': 'yang', 'jg': 'juga', 'jga': 'juga', 'ga': 'tidak', 'gak': 'tidak', 'gk': 'tidak',\n",
        "    'tdk': 'tidak', 'nggak': 'tidak', 'ngga': 'tidak', 'enggak': 'tidak',\n",
        "    'utk': 'untuk', 'buat': 'untuk', 'dr': 'dari', 'dp': 'dapat', 'dg': 'dengan',\n",
        "    'sy': 'saya', 'sya': 'saya', 'aku': 'saya', 'aq': 'saya', 'gua': 'saya', 'gw': 'saya',\n",
        "    'lu': 'kamu', 'loe': 'kamu', 'lo': 'kamu', 'km': 'kamu', 'kmu': 'kamu',\n",
        "    'apk': 'aplikasi', 'apknya': 'aplikasinya', 'app': 'aplikasi',\n",
        "    'bosssku': 'bosku', 'boskuhh': 'bosku', 'bossku': 'bosku',\n",
        "    'kaya': 'seperti', 'kyk': 'seperti', 'ky': 'seperti',\n",
        "    'kalo': 'kalau', 'kl': 'kalau', 'klu': 'kalau',\n",
        "    'udah': 'sudah', 'sdh': 'sudah', 'udh': 'sudah',\n",
        "    'aja': 'saja', 'doang': 'saja', 'tok': 'saja',\n",
        "    'blm': 'belum', 'bloom': 'belum',\n",
        "    'bgt': 'banget', 'bngt': 'banget', 'bgtss': 'banget', 'bangettt': 'banget',\n",
        "    'skrg': 'sekarang', 'skrng': 'sekarang',\n",
        "    'kmrn': 'kemarin', 'kmren': 'kemarin',\n",
        "    'besok2': 'besok-besok',\n",
        "    'bsk': 'besok',\n",
        "    'trs': 'terus', 'trus': 'terus',\n",
        "    'lg': 'lagi', 'lgi': 'lagi',\n",
        "    'mau': 'ingin', 'mo': 'mau',\n",
        "    'dpt': 'dapat', 'dapet': 'dapat',\n",
        "    'ntr': 'nanti', 'ntar': 'nanti',\n",
        "    'krn': 'karena', 'karna': 'karena',\n",
        "    'pdhl': 'padahal',\n",
        "    'org': 'orang',\n",
        "    'y' : 'ya',\n",
        "    'jd': 'jadi',\n",
        "    'ajaib': 'ajaib',  # biarkan karena bisa nama brand juga\n",
        "    'ni': 'ini', 'nih': 'ini',\n",
        "    'sih': '', 'deh': '', 'dong': '', 'ya': '', 'kok': '', 'lah': '',\n",
        "    'tp': 'tapi', 'tpn': 'tapi', 'tapii': 'tapi',\n",
        "    'btw': 'omong-omong',\n",
        "    'mantul': 'mantap betul', 'mantappp': 'mantap',\n",
        "    'ok': 'oke', 'okehh': 'oke',\n",
        "    'thx': 'terima kasih', 'makasih': 'terima kasih', 'mksh': 'terima kasih',\n",
        "    'trims': 'terima kasih', 'terimakasih': 'terima kasih',\n",
        "    'cpt': 'cepat', 'cepet': 'cepat', 'cepetan': 'cepat',\n",
        "    'lemot': 'lambat',\n",
        "    'parahh': 'parah', 'parahhh': 'parah',\n",
        "    'loyalti': 'loyalty',  # bisa jadi nama fitur\n",
        "    'driverny': 'drivernya', 'ojol': 'ojek online',\n",
        "    'cs': 'customer service',\n",
        "    'fiturnya': 'fitur',\n",
        "    'layananx': 'layanan',\n",
        "    'gaes': 'teman-teman', 'gengs': 'teman-teman',\n",
        "    'cashbacknya': 'cashback',\n",
        "    'promo2': 'promo-promo', 'promonya': 'promo',\n",
        "    'lok': 'lokasi',\n",
        "    'respon': 'respons',\n",
        "    'baguss': 'bagus', 'bgs': 'bagus', 'baguuus': 'bagus',\n",
        "    'burukk': 'buruk', 'jelekkk': 'jelek',\n",
        "    'ngaret': 'terlambat',\n",
        "    'delay': 'terlambat',\n",
        "    'crash': 'rusak',\n",
        "    'hang': 'macet',\n",
        "    'eror': 'error', 'erorr': 'error', 'erorrnya': 'error',\n",
        "    'kecewaaa': 'kecewa',\n",
        "    'toppp': 'top',\n",
        "    'makin': 'semakin',\n",
        "    'bingitz': 'banget',\n",
        "    'ribbed': 'ribet',\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        words = text.split()\n",
        "        normalized_words = [normalization_dict.get(word, word) for word in words]\n",
        "        return ' '.join(normalized_words)\n",
        "    return text\n",
        "\n",
        "df['normalized_content'] = df['cleaned_content'].apply(normalize_text)\n",
        "print(\"\\nDataset setelah normalisasi kata:\")\n",
        "print(df[['cleaned_content', 'normalized_content']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSvc-GUo3Cr6"
      },
      "source": [
        "Tokenisasi dan Penghapusan Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHEZlfP2FPZj"
      },
      "outputs": [],
      "source": [
        "sentiment_keywords = {\n",
        "    # Kata tanya yang menunjukkan keluhan atau masalah\n",
        "    \"kenapa\", \"mengapa\", \"bagaimana\", \"apa\", \"kok\",\n",
        "\n",
        "    # Kata kerja keluhan atau permintaan\n",
        "    \"perbaiki\", \"tolong\", \"hapus\", \"ganti\", \"perbarui\", \"hilangkan\", \"tambah\", \"kurangi\",\n",
        "\n",
        "    # Kata sifat bernuansa sentimen negatif\n",
        "    \"lemot\", \"lambat\", \"buruk\", \"jelek\", \"error\", \"macet\", \"susah\", \"ribet\", \"parah\", \"nge-bug\", \"crash\", \"hilang\",\n",
        "\n",
        "    # Kata sifat bernuansa sentimen positif\n",
        "    \"bagus\", \"mantap\", \"cepat\", \"mudah\", \"keren\", \"top\", \"oke\", \"hebat\", \"baik\",\n",
        "\n",
        "    # Kata ekspresif dan interjeksi yang bisa bernilai sentimen\n",
        "    \"yah\", \"duh\", \"astaga\", \"sayang\", \"wow\", \"alhamdulillah\", \"aduh\", \"please\", \"thanks\", \"terima\", \"syukur\",\n",
        "\n",
        "    # Kata berkaitan dengan fungsi aplikasi\n",
        "    \"login\", \"bayar\", \"pesan\", \"promo\", \"diskon\", \"voucher\", \"fitur\", \"layanan\", \"akses\", \"notifikasi\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtP9f2MRFQxj"
      },
      "outputs": [],
      "source": [
        "# Ubah stopword jadi set\n",
        "stop_words = set(stop_words)\n",
        "\n",
        "# Hapus kata-kata penting dari daftar stopwords\n",
        "stop_words -= sentiment_keywords  # buang dari stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeskHJsR2c4n",
        "outputId": "b4b95e6f-a266-41fb-89a7-03b050c2cdfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset setelah tokenisasi dan penghapusan stopwords:\n",
            "                                  normalized_content  \\\n",
            "0                            akun gopay saya di blok   \n",
            "1  lambat sekali sekarang ini bosku aplikasi goje...   \n",
            "2  kenapa  dari kemarin saya buka aplikasi gojek ...   \n",
            "3  baru download gojek dan hape baru terus ditop ...   \n",
            "4                                             mantap   \n",
            "\n",
            "                                   tokenized_content  \n",
            "0                                [akun, gopay, blok]  \n",
            "1                   [lambat, bosku, aplikasi, gojek]  \n",
            "2  [kenapa, kemarin, buka, aplikasi, gojek, kasih...  \n",
            "3  [download, gojek, hape, ditop, u, gopay, trans...  \n",
            "4                                           [mantap]  \n"
          ]
        }
      ],
      "source": [
        "def tokenize_and_remove_stopwords(text):\n",
        "    if isinstance(text, str):\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word for word in tokens if word not in stop_words and word.isalpha()] # Hapus stopwords dan token non-alfabet\n",
        "        return tokens\n",
        "    return []\n",
        "\n",
        "df['tokenized_content'] = df['normalized_content'].apply(tokenize_and_remove_stopwords)\n",
        "print(\"\\nDataset setelah tokenisasi dan penghapusan stopwords:\")\n",
        "print(df[['normalized_content', 'tokenized_content']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrzQvG3F3xqh"
      },
      "source": [
        "Stemming/Lemmatization (Menggunakan Sastrawi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP6AcYF906bF",
        "outputId": "2b4eeb52-6c80-436c-c1e2-adab66c9cc3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1Rjhd_O03Q-",
        "outputId": "f1f82e98-fc4f-4ec1-f56b-3b80feb64019"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stemming: 100%|██████████| 225002/225002 [2:05:22<00:00, 29.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset setelah stemming:\n",
            "                                   tokenized_content  \\\n",
            "0                                [akun, gopay, blok]   \n",
            "1                   [lambat, bosku, aplikasi, gojek]   \n",
            "2  [kenapa, kemarin, buka, aplikasi, gojek, kasih...   \n",
            "3  [download, gojek, hape, ditop, u, gopay, trans...   \n",
            "4                                           [mantap]   \n",
            "\n",
            "                                   processed_content  \n",
            "0                                    akun gopay blok  \n",
            "1                          lambat bos aplikasi gojek  \n",
            "2  kenapa kemarin buka aplikasi gojek kasih binta...  \n",
            "3  download gojek hape top u gopay transaksi dial...  \n",
            "4                                             mantap  \n",
            "\n",
            "Jumlah baris data setelah preprocessing: 223855\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Tqdm support for pandas apply\n",
        "tqdm.pandas(desc=\"Stemming\")\n",
        "\n",
        "def stem_text(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "# Terapkan stemming dengan progress bar\n",
        "df['processed_content'] = df['tokenized_content'].progress_apply(lambda tokens: ' '.join(stem_text(tokens)))\n",
        "\n",
        "print(\"\\nDataset setelah stemming:\")\n",
        "print(df[['tokenized_content', 'processed_content']].head())\n",
        "\n",
        "# Hapus baris kosong setelah preprocessing\n",
        "df = df[df['processed_content'].str.strip().astype(bool)]\n",
        "print(f\"\\nJumlah baris data setelah preprocessing: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-YiVMnRSDGM",
        "outputId": "b959d765-0d0e-4c5b-e274-ce09321c5fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame hasil preprocessing telah disimpan di runtime.\n"
          ]
        }
      ],
      "source": [
        "df.to_csv('processed_gojek_reviews.csv', index=False)\n",
        "\n",
        "print(\"\\nDataFrame hasil preprocessing telah disimpan di runtime.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}